{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d287a6",
   "metadata": {},
   "source": [
    "# PLINK pre-QC in Bash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13199ed5",
   "metadata": {},
   "source": [
    "\"Ride the PLINK wave.\" - Cristina\n",
    "\n",
    "**Creating plink command to extract individuals for which eye colour data is available**\n",
    "\n",
    "Files by the name \"dataset_eyelist.txt\" were created in the phenotype info documentation and are used as reference lists for keeping only the individuals who provided self-reported eye colour information. \n",
    "\n",
    "PLINK input filtering documentation can be found here: https://www.cog-genomics.org/plink/2.0/filter\n",
    "\n",
    "Another useful resource for PLINK syntax can be found here: https://zzz.bwh.harvard.edu/plink/dataman.shtml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9face2",
   "metadata": {},
   "source": [
    "### Some notes for identifying the binary files\n",
    "\n",
    "Refer to release notes under GRU to locate the following binary files:\n",
    "\n",
    "**GENEVA**\n",
    "\n",
    "    HapMap Controls: phg000070.v1.p1.GENEVA_Melanoma.genotype-calls-matrixfmt.MULTI.HapMap_controls.tar \n",
    "\n",
    "    Cases: phg000070.v1.p1.GENEVA_Melanoma.genotype-calls-matrixfmt.c1.GRU.tar \n",
    "\n",
    "    Controls: phg000094.v1.p1.GENEVA_Melanoma_CONTROLS.genotype-calls-matrixfmt.c1.GRU.tar \n",
    "\n",
    "**CIDR**\n",
    "\n",
    "    HapMap Controls: phg000428.v1.CIDR_Melanoma_AuUK.genotype-calls-matrixfmt.MULTI.HapMap.tar\n",
    "\n",
    "    Cases: phg000428.v1.CIDR_Melanoma_AuUK.genotype-calls-matrixfmt.c1.GRU-MDS.tar\n",
    "\n",
    "\n",
    "**Duke**\n",
    "\n",
    "    Human_1M: phg001278.v1.ImplicationsForDisease.genotype-calls-matrixfmt.Human_1M.c1.GRU-IRB-PUB.tar.gz\n",
    "\n",
    "    Exome: phg001278.v1.ImplicationsForDisease.genotype-calls-matrixfmt.ExomeChip.c1.GRU-IRB-PUB.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frank CanPath data\n",
    "./plink --bfile ATL_GENO --keep atl_eyelist.txt --make-bed --out ATL_eye\n",
    "./plink --bfile ATP_GENO --keep atp_eyelist.txt --make-bed --out ATP_eye\n",
    "./plink --bfile BCGP_GENO --keep bcgp_eyelist.txt --make-bed --out BCGP_eye\n",
    "./plink --bfile OHS_GENO --keep ohs_eyelist.txt --make-bed --out OHS_eye\n",
    "\n",
    "#Cristina CARTaGENE data (done qc and imputation already)\n",
    "./plink --bfile CaG_GENO --keep cag_eyelist.txt --make-bed --out CaG_eye\n",
    "\n",
    "#CIDR\n",
    "./plink --bfile CIDR_Melanoma_AU_UK_Top_sample_level_c1 --keep CIDR_eyelist.txt --make-bed --out CIDR_CASES_eye\n",
    "\n",
    "#DUKE\n",
    "./plink --bfile dcc_deid_gwas_to_upload --keep DUKE_eyelist.txt --make-bed --out Duke_1M_eye\n",
    "\n",
    "#GENEVA\n",
    "./plink --bfile GENEVA_Melanoma_FORWARD_GRU --keep GENEVA_eyelist_v2.txt --make-bed --out GENEVA_CASES_eye\n",
    "./plink --bfile GENEVA_Melanoma_FORWARD_CONTROLS_sample_level --keep GENEVA_eyelist_v2.txt --make-bed --out GENEVA_CONTROLS_eye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c010f",
   "metadata": {},
   "source": [
    "# PLINK QC in Bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e20910",
   "metadata": {},
   "source": [
    "QC follows steps outlined in Marees et al. 2018.\n",
    "\n",
    "Pre-imputation QC steps:\n",
    "1. SNP QC, keep all SNPs with call rate > 0.95\n",
    "\n",
    "\n",
    "2. Sample QC, keep all samples with\n",
    "    \n",
    "    a. Call rate > 0.95\n",
    "    \n",
    "    b. Sex check\n",
    "    \n",
    "    \n",
    "3. SNP QC (again) â€“ keep all SNPs with:\n",
    "\n",
    "    a. Call rate > 0.98\n",
    "    \n",
    "    b. Missingness < 0.02\n",
    "    \n",
    "    c. MAF > 1%\n",
    "    \n",
    "    d. HWE p-values > 1e-6\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c366a969",
   "metadata": {},
   "source": [
    "**Missingness Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f079057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: ./plink: No such file or directory\n",
      "Fatal error: cannot open file 'hist_miss.R': No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "2",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# OHS\n",
    "./plink --bfile OHS_eye --missing --out OHS_miss\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye --missing --out BCGP_miss\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye --missing --out ATL_miss\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye --missing --out ATP_miss\n",
    "\n",
    "# CIDR\n",
    "./plink --bfile CIDR_CASES_eye --missing --out CIDR_miss\n",
    "\n",
    "# DUKE\n",
    "./plink --bfile DUKE_1M_eye --missing --out DUKE_miss\n",
    "\n",
    "# GENEVA\n",
    "./plink --bfile GENEVA_CASES_eye --missing --out GENEVA_CASES_miss\n",
    "./plink --bfile GENEVA_CONTROLS_eye --missing --out GENEVA_CONTROLS_miss\n",
    "\n",
    "# At this point, run either the following bash commands or run the missingness check manually from the QC_scripts.R file.\n",
    "Rscript --no-save OHS_hist_miss.R\n",
    "Rscript --no-save BCGP_hist_miss.R\n",
    "Rscript --no-save ATL_hist_miss.R\n",
    "Rscript --no-save ATP_hist_miss.R\n",
    "Rscript --no-save CIDR_hist_miss.R\n",
    "Rscript --no-save DUKE_hist_miss.R\n",
    "Rscript --no-save GENEVA_hist_miss.R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b86340",
   "metadata": {},
   "source": [
    "### STEP 1\n",
    "**SNP QC, keep all SNPs with call rate > 0.95**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a138242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHS\n",
    "./plink --bfile OHS_eye --geno 0.05 --make-bed --out OHS_eye_s1\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye --geno 0.05 --make-bed --out BCGP_eye_s1\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye --geno 0.05 --make-bed --out ATL_eye_s1\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye --geno 0.05 --make-bed --out ATP_eye_s1\n",
    "\n",
    "# CIDR\n",
    "./plink --bfile CIDR_CASES_eye --geno 0.05 --make-bed --out CIDR_eye_s1\n",
    "\n",
    "# DUKE\n",
    "./plink --bfile DUKE_1M_eye --geno 0.05 --make-bed --out DUKE_eye_s1\n",
    "\n",
    "# GENEVA\n",
    "./plink --bfile GENEVA_CASES_eye --geno 0.05 --make-bed --out GENEVA_CASES_eye_s1\n",
    "./plink --bfile GENEVA_CONTROLS_eye --geno 0.05 --make-bed --out GENEVA_CONTROLS_eye_s1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2281c",
   "metadata": {},
   "source": [
    "### STEP 2\n",
    "**Sample QC, keep all samples with call rate > 0.98 and performing sex check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ba3328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n",
      "Fatal error: cannot open file 'sex_check.R': No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "2",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# OHS\n",
    "./plink --bfile OHS_eye_s1 --mind 0.02 --make-bed --out OHS_eye_s1_s2\n",
    "./plink --bfile OHS_eye_s1_s2 --check-sex --out OHS_sex\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye_s1 --mind 0.02 --make-bed --out BCGP_eye_s1_s2\n",
    "./plink --bfile BCGP_eye_s1_s2 --check-sex --out BCGP_sex\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye_s1 --mind 0.02 --make-bed --out ATL_eye_s1_s2\n",
    "./plink --bfile ATL_eye_s1_s2 --check-sex --out ATL_sex\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye_s1 --mind 0.02 --make-bed --out ATP_eye_s1_s2\n",
    "./plink --bfile ATP_eye_s1_s2 --check-sex --out ATP_sex\n",
    "\n",
    "# CIDR\n",
    "./plink --bfile CIDR_eye_s1 --mind 0.02 --make-bed --out CIDR_eye_s1_s2\n",
    "./plink --bfile CIDR_eye_s1_s2 --check-sex --out CIDR_sex\n",
    "\n",
    "# DUKE\n",
    "./plink --bfile DUKE_eye_s1 --mind 0.02 --make-bed --out DUKE_eye_s1_s2\n",
    "./plink --bfile DUKE_eye_s1_s2 --check-sex --out DUKE_sex\n",
    "\n",
    "# GENEVA\n",
    "./plink --bfile GENEVA_CASES_eye_s1 --mind 0.02 --make-bed --out GENEVA_CASES_eye_s1_s2\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1 --mind 0.02 --make-bed --out GENEVA_CONTROLS_eye_s1_s2\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2 --check-sex --out GENEVA_CASES_sex\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2 --check-sex --out GENEVA_CONTROLS_sex\n",
    "\n",
    "# At this point, run either the following bash commands or run the sex check manually from the QC_scripts.R file.\n",
    "Rscript --no-save OHS_sex_check.R\n",
    "Rscript --no-save BCGP_sex_check.R\n",
    "Rscript --no-save ATL_sex_check.R\n",
    "Rscript --no-save ATP_sex_check.R\n",
    "Rscript --no-save CIDR_sex_check.R\n",
    "Rscript --no-save DUKE_sex_check.R\n",
    "Rscript --no-save GENEVA_sex_check.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c975e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two ways to deal with sex discrepancy.\n",
    "    # If there are >~20 individuals with sex discrepancy, impute sex.\n",
    "    # If there are <20 individuals, remove them.\n",
    "\n",
    "# 1) Remove individuals with sex discrepancy.\n",
    "grep \"PROBLEM\" CIDR_sex.sexcheck| awk '{print$1,$2}' > CIDR_sex_discrepancy.txt\n",
    "grep \"PROBLEM\" DUKE_sex.sexcheck| awk '{print$1,$2}' > DUKE_sex_discrepancy.txt\n",
    "grep \"PROBLEM\" GENEVA_CASES_sex.sexcheck| awk '{print$1,$2}' > GENEVA_CASES_sex_discrepancy.txt\n",
    "grep \"PROBLEM\" GENEVA_CONTROLS_sex.sexcheck| awk '{print$1,$2}' > GENEVA_CONTROLS_sex_discrepancy.txt\n",
    "# This command generates a list of individuals with the status \"PROBLEM\".\n",
    "\n",
    "./plink --bfile CIDR_eye_s1_s2 --remove CIDR_sex_discrepancy.txt --make-bed --out CIDR_eye_s1_s2_sex\n",
    "./plink --bfile DUKE_eye_s1_s2 --remove DUKE_sex_discrepancy.txt --make-bed --out DUKE_eye_s1_s2_sex\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2 --remove GENEVA_CASES_sex_discrepancy.txt --make-bed --out GENEVA_CASES_eye_s1_s2_sex\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2 --remove GENEVA_CONTROLS_sex_discrepancy.txt --make-bed --out GENEVA_CONTROLS_eye_s1_s2_sex\n",
    "# This command removes the list of individuals with the status \"PROBLEM\".\n",
    "\n",
    "# OR\n",
    "\n",
    "# 2) Impute sex - CanPath .fam files do not contain sex information, so we skipped sex imputation\n",
    "./plink --bfile CIDR_eye_s1_s2 --impute-sex --make-bed --out CIDR_eye_s1_s2_sex\n",
    "./plink --bfile DUKE_eye_s1_s2 --impute-sex --make-bed --out DUKE_eye_s1_s2_sex\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2 --impute-sex --make-bed --out GENEVA_CASES_eye_s1_s2_sex\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2 --impute-sex --make-bed --out GENEVA_CONTROLS_eye_s1_s2_sex\n",
    "# This imputes the sex based on the genotype information in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cde468",
   "metadata": {},
   "source": [
    "### STEP 3\n",
    "**SNP QC again, keep all SNPS with call rate > 0.98, missingness < 0.02**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b08e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHS\n",
    "./plink --bfile OHS_eye_s1_s2 --geno 0.02 --make-bed --out OHS_eye_s1_s2_sex_s3\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye_s1_s2 --geno 0.02 --make-bed --out BCGP_eye_s1_s2_sex_s3\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye_s1_s2 --geno 0.02 --make-bed --out ATL_eye_s1_s2_sex_s3\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye_s1_s2 --geno 0.02 --make-bed --out ATP_eye_s1_s2_sex_s3\n",
    "\n",
    "# CIDR\n",
    "./plink --bfile CIDR_eye_s1_s2 --geno 0.02 --make-bed --out CIDR_eye_s1_s2_sex_s3\n",
    "\n",
    "# DUKE\n",
    "./plink --bfile DUKE_eye_s1_s2 --geno 0.02 --make-bed --out DUKE_eye_s1_s2_sex_s3\n",
    "\n",
    "# GENEVA\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2 --geno 0.02 --make-bed --out GENEVA_CASES_eye_s1_s2_sex_s3\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2 --geno 0.02 --make-bed --out GENEVA_CONTROLS_eye_s1_s2_sex_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf1f5de",
   "metadata": {},
   "source": [
    "**Keep all SNPs with MAF > 1%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb54d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awk: can't open file OHS_eye_s1_s2_sex.bim\n",
      " source line number 1\n",
      "bash: ./plink: No such file or directory\n",
      "awk: can't open file OHS_eye_s1_s2_sex.bim\n",
      " source line number 1\n",
      "bash: ./plink: No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "127",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "## This selects autosomal SNPs only (i.e., from chromosomes 1 to 22):\n",
    "\n",
    "# OHS\n",
    "awk '{ if ($1 >= 1 && $1 <= 22) print $2 }' OHS_eye_s1_s2_sex_s3.bim > OHS_snp_1_22.txt\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3 --extract OHS_snp_1_22.txt --make-bed --out OHS_eye_s1_s2_sex_s3_auto\n",
    "\n",
    "# BCGP\n",
    "awk '{ if ($1 >= 1 && $1 <= 22) print $2 }' BCGP_eye_s1_s2_sex_s3.bim > BCGP_snp_1_22.txt\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3 --extract BCGP_snp_1_22.txt --make-bed --out BCGP_eye_s1_s2_sex_s3_auto\n",
    "\n",
    "# ATL\n",
    "awk '{ if ($1 >= 1 && $1 <= 22) print $2 }' ATL_eye_s1_s2_sex_s3.bim > ATL_snp_1_22.txt\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3 --extract ATL_snp_1_22.txt --make-bed --out ATL_eye_s1_s2_sex_s3_auto\n",
    "\n",
    "# ATP\n",
    "awk '{ if ($1 >= 1 && $1 <= 22) print $2 }' ATP_eye_s1_s2_sex_s3.bim > ATP_snp_1_22.txt\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3 --extract ATP_snp_1_22.txt --make-bed --out ATP_eye_s1_s2_sex_s3_auto\n",
    "\n",
    "# CIDR\n",
    "awk '{ if ($1 >= 1 && $1 <= 22) print $2 }' CIDR_eye_s1_s2_sex_s3.bim > CIDR_snp_1_22.txt\n",
    "./plink --bfile CIDR_eye_s1_s2_sex_s3 --extract CIDR_snp_1_22.txt --make-bed --out CIDR_eye_s1_s2_sex_s3_auto\n",
    "\n",
    "# DUKE\n",
    "awk '{ if ($1 >= 1 && $1 <= 22) print $2 }' DUKE_eye_s1_s2_sex_s3.bim > DUKE_snp_1_22.txt\n",
    "./plink --bfile DUKE_eye_s1_s2_sex_s3 --extract DUKE_snp_1_22.txt --make-bed --out DUKE_eye_s1_s2_sex_s3_auto\n",
    "\n",
    "# GENEVA\n",
    "awk '{ if ($1 >= 1 && $1 <= 22) print $2 }' GENEVA_CASES_eye_s1_s2_sex_s3.bim > GENEVA_CASES_snp_1_22.txt\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2_sex_s3 --extract GENEVA_CASES_snp_1_22.txt --make-bed --out GENEVA_CASES_eye_s1_s2_sex_s3_auto\n",
    "awk '{ if ($1 >= 1 && $1 <= 22) print $2 }' GENEVA_CONTROLS_eye_s1_s2_sex_s3.bim > GENEVA_CONTROLS_snp_1_22.txt\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2_sex_s3 --extract GENEVA_CONTROLS_snp_1_22.txt --make-bed --out GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5116ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This generates a plot of the MAF distribution:\n",
    "\n",
    "# OHS\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_auto --freq --out OHS_MAF_check\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_auto --freq --out BCGP_MAF_check\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_auto --freq --out ATL_MAF_check\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_auto --freq --out ATP_MAF_check\n",
    "\n",
    "# CIDR\n",
    "./plink --bfile CIDR_eye_s1_s2_sex_s3_auto --freq --out CIDR_MAF_check\n",
    "\n",
    "# DUKE\n",
    "./plink --bfile DUKE_eye_s1_s2_sex_s3_auto --freq --out DUKE_MAF_check\n",
    "\n",
    "# GENEVA\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2_sex_s3_auto --freq --out GENEVA_CASES_MAF_check\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto --freq --out GENEVA_CONTROLS_MAF_check\n",
    "\n",
    "# At this point, run either the following bash commands or run the MAF check manually from the QC_scripts.R file.\n",
    "Rscript --no-save OHS_MAF_check.R\n",
    "Rscript --no-save BCGP_MAF_check.R\n",
    "Rscript --no-save ATL_MAF_check.R\n",
    "Rscript --no-save ATP_MAF_check.R\n",
    "Rscript --no-save CIDR_MAF_check.R\n",
    "Rscript --no-save DUKE_MAF_check.R\n",
    "Rscript --no-save GENEVA_MAF_check.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf330d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "127",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "## Remove low MAF SNPs:\n",
    "\n",
    "# OHS\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_auto --maf 0.01 --make-bed --out OHS_eye_s1_s2_sex_s3_auto_maf\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_auto --maf 0.01 --make-bed --out BCGP_eye_s1_s2_sex_s3_auto_maf\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_auto --maf 0.01 --make-bed --out ATL_eye_s1_s2_sex_s3_auto_maf\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_auto --maf 0.01 --make-bed --out ATP_eye_s1_s2_sex_s3_auto_maf\n",
    "\n",
    "# CIDR\n",
    "./plink --bfile CIDR_eye_s1_s2_sex_s3_auto --maf 0.01 --make-bed --out CIDR_eye_s1_s2_sex_s3_auto_maf\n",
    "\n",
    "# DUKE\n",
    "./plink --bfile DUKE_eye_s1_s2_sex_s3_auto --maf 0.01 --make-bed --out DUKE_eye_s1_s2_sex_s3_auto_maf\n",
    "\n",
    "# GENEVA\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2_sex_s3_auto --maf 0.01 --make-bed --out GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto --maf 0.01 --make-bed --out GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd11087a",
   "metadata": {},
   "source": [
    "**Keep all SNPs with HWEp > 1e-6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b842103",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the distribution of HWE p-values of all SNPs:\n",
    "\n",
    "# OHS\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_auto_maf --hardy --out OHS_hwe\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_auto_maf --hardy --out BCGP_hwe\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_auto_maf --hardy --out ATL_hwe\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_auto_maf --hardy --out ATP_hwe\n",
    "\n",
    "# CIDR\n",
    "./plink --bfile CIDR_eye_s1_s2_sex_s3_auto_maf --hardy --out CIDR_hwe\n",
    "\n",
    "# DUKE\n",
    "./plink --bfile DUKE_eye_s1_s2_sex_s3_auto_maf --hardy --out DUKE_hwe\n",
    "\n",
    "# GENEVA\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf --hardy --out GENEVA_CASES_hwe\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf --hardy --out GENEVA_CONTROLS_hwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56838e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting SNPs with HWE p-value below 0.00001, required for one of the two plot generated by the next Rscript, allows to zoom in on strongly deviating SNPs. \n",
    "\n",
    "# OHS\n",
    "awk '{ if ($9 < 0.00001) print $0 }' OHS_hwe.hwe > OHS_hwe_zoomhwe.hwe\n",
    "\n",
    "# BCGP\n",
    "awk '{ if ($9 < 0.00001) print $0 }' BCGP_hwe.hwe > BCGP_hwe_zoomhwe.hwe\n",
    "\n",
    "# ATL\n",
    "awk '{ if ($9 < 0.00001) print $0 }' ATL_hwe.hwe > ATL_hwe_zoomhwe.hwe\n",
    "\n",
    "# ATP\n",
    "awk '{ if ($9 < 0.00001) print $0 }' ATP_hwe.hwe > ATP_hwe_zoomhwe.hwe\n",
    "\n",
    "# CIDR\n",
    "awk '{ if ($9 < 0.00001) print $0 }' CIDR_hwe.hwe > CIDR_hwe_zoomhwe.hwe\n",
    "\n",
    "# DUKE\n",
    "awk '{ if ($9 < 0.00001) print $0 }' DUKE_hwe.hwe > DUKE_hwe_zoomhwe.hwe\n",
    "\n",
    "# GENEVA\n",
    "awk '{ if ($9 < 0.00001) print $0 }' GENEVA_CASES_hwe.hwe > GENEVA_CASES_hwe_zoomhwe.hwe\n",
    "awk '{ if ($9 < 0.00001) print $0 }' GENEVA_CONTROLS_hwe.hwe > GENEVA_CONTROLS_hwe_zoomhwe.hwe\n",
    "\n",
    "# At this point, run either the following bash commands or run the HWE check manually from the QC_scripts.R file.\n",
    "Rscript --no-save OHS_hwe.R\n",
    "Rscript --no-save BCGP_hwe.R\n",
    "Rscript --no-save ATL_hwe.R\n",
    "Rscript --no-save ATP_hwe.R\n",
    "Rscript --no-save CIDR_hwe.R\n",
    "Rscript --no-save DUKE_hwe.R\n",
    "Rscript --no-save GENEVA_hwe.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Consider if you need to filter for both cases and controls.\n",
    "\n",
    "    # if not (applies the same threshold to cases and controls): \n",
    "\n",
    "# OHS\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_auto_maf --hwe 1e-6 include-nonctrl --make-bed --out OHS_eye_s1_s2_sex_s3_auto_maf_hwe\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_auto_maf --hwe 1e-6 include-nonctrl --make-bed --out BCGP_eye_s1_s2_sex_s3_auto_maf_hwe\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_auto_maf --hwe 1e-6 include-nonctrl --make-bed --out ATL_eye_s1_s2_sex_s3_auto_maf_hwe\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_auto_maf --hwe 1e-6 include-nonctrl --make-bed --out ATP_eye_s1_s2_sex_s3_auto_maf_hwe\n",
    "\n",
    "# CIDR\n",
    "./plink --bfile CIDR_eye_s1_s2_sex_s3_auto_maf --hwe 1e-6 include-nonctrl --make-bed --out CIDR_eye_s1_s2_sex_s3_auto_maf_hwe\n",
    "\n",
    "# DUKE\n",
    "./plink --bfile DUKE_eye_s1_s2_sex_s3_auto_maf --hwe 1e-6 include-nonctrl --make-bed --out DUKE_eye_s1_s2_sex_s3_auto_maf_hwe\n",
    "\n",
    "# GENEVA\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf --hwe 1e-6 include-nonctrl --make-bed --out GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf_hwe\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf --hwe 1e-6 include-nonctrl --make-bed --out GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf_hwe\n",
    "\n",
    "    # if yes (applies a less stringent threshold to cases (1e-10)):\n",
    "    \n",
    "# OHS\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_auto_maf --hwe 1e-10 --make-bed --out OHS_eye_s1_s2_sex_s3_auto_maf_hwe1\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_auto_maf_hwe1 --hwe 1e-6 include-nonctrl --make-bed --out OHS_eye_s1_s2_sex_s3_auto_maf_hwe2_clean1\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_auto_maf --hwe 1e-10 --make-bed --out BCGP_eye_s1_s2_sex_s3_auto_maf_hwe1\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_auto_maf_hwe1 --hwe 1e-6 include-nonctrl --make-bed --out BCGP_eye_s1_s2_sex_s3_auto_maf_hwe2_clean1\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_auto_maf --hwe 1e-10 --make-bed --out ATL_eye_s1_s2_sex_s3_auto_maf_hwe1\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_auto_maf_hwe1 --hwe 1e-6 include-nonctrl --make-bed --out ATL_eye_s1_s2_sex_s3_auto_maf_hwe2_clean1\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_auto_maf --hwe 1e-10 --make-bed --out ATP_eye_s1_s2_sex_s3_auto_maf_hwe1\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_auto_maf_hwe1 --hwe 1e-6 include-nonctrl --make-bed --out ATP_eye_s1_s2_sex_s3_auto_maf_hwe2_clean1\n",
    "\n",
    "# CIDR\n",
    "./plink --bfile CIDR_eye_s1_s2_sex_s3_auto_maf --hwe 1e-10 --make-bed --out CIDR_eye_s1_s2_sex_s3_auto_maf_hwe1\n",
    "./plink --bfile CIDR_eye_s1_s2_sex_s3_auto_maf_hwe1 --hwe 1e-6 include-nonctrl --make-bed --out CIDR_eye_s1_s2_sex_s3_auto_maf_hwe2_clean1\n",
    "\n",
    "# DUKE\n",
    "./plink --bfile DUKE_eye_s1_s2_sex_s3_auto_maf --hwe 1e-10 --make-bed --out DUKE_eye_s1_s2_sex_s3_auto_maf_hwe1\n",
    "./plink --bfile DUKE_eye_s1_s2_sex_s3_auto_maf_hwe1 --hwe 1e-6 include-nonctrl --make-bed --out DUKE_eye_s1_s2_sex_s3_auto_maf_hwe2_clean1\n",
    "\n",
    "# GENEVA\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf --hwe 1e-10 --make-bed --out GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf_hwe1\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf_hwe1 --hwe 1e-6 include-nonctrl --make-bed --out GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf_hwe2_clean1\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf --hwe 1e-10 --make-bed --out GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf_hwe1\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf_hwe1 --hwe 1e-6 include-nonctrl --make-bed --out GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf_hwe2_clean1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4dbac7",
   "metadata": {},
   "source": [
    "### STEP 4\n",
    "This is according to the Marees et al. tutorial:\n",
    "\n",
    "**Removing Related Individuals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ccd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is essential to check datasets you analyse for cryptic relatedness.\n",
    "# Assuming a random population sample, we exclude all individuals above pihat threshold of 0.2.\n",
    "# The HapMap dataset is known to contain parent-offspring relations. \n",
    "# Check for relationships between individuals with a pihat > 0.2, then visualize these parent-offspring relations using z values. \n",
    "\n",
    "# OHS\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_auto_maf_hwe --genome --min 0.2 --out OHS_pihat_min0.2\n",
    "awk '{ if ($8 >0.9) print $0 }' OHS_pihat_min0.2.genome > OHS_zoom_pihat.genome\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_auto_maf_hwe --genome --min 0.2 --out BCGP_pihat_min0.2\n",
    "awk '{ if ($8 >0.9) print $0 }' BCGP_pihat_min0.2.genome > BCGP_zoom_pihat.genome\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_auto_maf_hwe --genome --min 0.2 --out ATL_pihat_min0.2\n",
    "awk '{ if ($8 >0.9) print $0 }' ATL_pihat_min0.2.genome > ATL_zoom_pihat.genome\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_auto_maf_hwe --genome --min 0.2 --out ATP_pihat_min0.2\n",
    "awk '{ if ($8 >0.9) print $0 }' ATP_pihat_min0.2.genome > ATP_zoom_pihat.genome\n",
    "\n",
    "# CIDR\n",
    "./plink --bfile CIDR_eye_s1_s2_sex_s3_auto_maf_hwe --genome --min 0.2 --out CIDR_pihat_min0.2\n",
    "awk '{ if ($8 >0.9) print $0 }' CIDR_pihat_min0.2.genome > CIDR_zoom_pihat.genome\n",
    "\n",
    "# DUKE\n",
    "./plink --bfile DUKE_eye_s1_s2_sex_s3_auto_maf_hwe --genome --min 0.2 --out DUKE_pihat_min0.2\n",
    "awk '{ if ($8 >0.9) print $0 }' DUKE_pihat_min0.2.genome > DUKE_zoom_pihat.genome\n",
    "\n",
    "# GENEVA\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf_hwe --genome --min 0.2 --out GENEVA_CASES_pihat_min0.2\n",
    "awk '{ if ($8 >0.9) print $0 }' GENEVA_CASES_pihat_min0.2.genome > GENEVA_CASES_zoom_pihat.genome\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf_hwe --genome --min 0.2 --out GENEVA_CONTROLS_pihat_min0.2\n",
    "awk '{ if ($8 >0.9) print $0 }' GENEVA_CONTROLS_pihat_min0.2.genome > GENEVA_CONTROLS_zoom_pihat.genome\n",
    "\n",
    "\n",
    "# At this point, run either the following bash commands or run the relatedness check manually from the QC_scripts.R file.\n",
    "Rscript --no-save OHS_Relatedness.R\n",
    "Rscript --no-save BCGP_Relatedness.R\n",
    "Rscript --no-save ATL_Relatedness.R\n",
    "Rscript --no-save ATP_Relatedness.R\n",
    "Rscript --no-save CIDR_Relatedness.R\n",
    "Rscript --no-save DUKE_Relatedness.R\n",
    "Rscript --no-save GENEVA_Relatedness.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8869463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include only founders (individuals without parents in the dataset).\n",
    "# Look again for individuals with a pihat > 0.2.\n",
    "# For each pair of 'related' individuals with a pihat > 0.2, remove the individual with the lowest call rate. \n",
    "\n",
    "# OHS\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_auto_maf_hwe --filter-founders --make-bed --out OHS_eye_s1_s2_sex_s3_auto_maf_hwe_founders\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_auto_maf_hwe_founders --genome --min 0.2 --out OHS_pihat_min0.2_in_founders\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_auto_maf_hwe_founders --missing --out OHS_related_miss\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_auto_maf_hwe --filter-founders --make-bed --out BCGP_eye_s1_s2_sex_s3_auto_maf_hwe_founders\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_auto_maf_hwe_founders --genome --min 0.2 --out BCGP_pihat_min0.2_in_founders\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_auto_maf_hwe_founders --missing --out BCGP_related_miss\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_auto_maf_hwe --filter-founders --make-bed --out ATL_eye_s1_s2_sex_s3_auto_maf_hwe_founders\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_auto_maf_hwe_founders --genome --min 0.2 --out ATL_pihat_min0.2_in_founders\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_auto_maf_hwe_founders --missing --out ATL_related_miss\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_auto_maf_hwe --filter-founders --make-bed --out ATP_eye_s1_s2_sex_s3_auto_maf_hwe_founders\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_auto_maf_hwe_founders --genome --min 0.2 --out ATP_pihat_min0.2_in_founders\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_auto_maf_hwe_founders --missing --out ATP_related_miss\n",
    "\n",
    "# CIDR\n",
    "./plink --bfile CIDR_eye_s1_s2_sex_s3_auto_maf_hwe --filter-founders --make-bed --out CIDR_eye_s1_s2_sex_s3_auto_maf_hwe_founders\n",
    "./plink --bfile CIDR_eye_s1_s2_sex_s3_auto_maf_hwe_founders --genome --min 0.2 --out CIDR_pihat_min0.2_in_founders\n",
    "./plink --bfile CIDR_eye_s1_s2_sex_s3_auto_maf_hwe_founders --missing --out CIDR_related_miss\n",
    "\n",
    "# DUKE\n",
    "./plink --bfile DUKE_eye_s1_s2_sex_s3_auto_maf_hwe --filter-founders --make-bed --out DUKE_eye_s1_s2_sex_s3_auto_maf_hwe_founders\n",
    "./plink --bfile DUKE_eye_s1_s2_sex_s3_auto_maf_hwe_founders --genome --min 0.2 --out DUKE_pihat_min0.2_in_founders\n",
    "./plink --bfile DUKE_eye_s1_s2_sex_s3_auto_maf_hwe_founders --missing --out DUKE_related_miss\n",
    "\n",
    "# GENEVA\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf_hwe --filter-founders --make-bed --out GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf_hwe_founders\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf_hwe_founders --genome --min 0.2 --out GENEVA_CASES_pihat_min0.2_in_founders\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf_hwe_founders --missing --out GENEVA_CASES_related_miss\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf_hwe --filter-founders --make-bed --out GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf_hwe_founders\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf_hwe_founders --genome --min 0.2 --out GENEVA_CONTROLS_pihat_min0.2_in_founders\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf_hwe_founders --missing --out GENEVA_CONTROLS_related_miss\n",
    "\n",
    "\n",
    "# Use a UNIX text editor (e.g., vi(m) ) to check which individual has the highest call rate in the 'related pair'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of FID and IID of the individual(s) with a Pihat above 0.2, to check who had the lower call rate of the pair.\n",
    "# In our dataset the individual 13291  NA07045 had the lower call rate.\n",
    "\n",
    "# OHS\n",
    "vi OHS_0.2_low_call_rate_pihat.txt\n",
    "i \n",
    "13291  NA07045\n",
    "# Press esc\n",
    ":x\n",
    "# Press enter\n",
    "\n",
    "# BCGP\n",
    "vi BCGP_0.2_low_call_rate_pihat.txt\n",
    "i \n",
    "13291  NA07045\n",
    "# Press esc\n",
    ":x\n",
    "# Press enter\n",
    "\n",
    "# ATL\n",
    "vi ATL_0.2_low_call_rate_pihat.txt\n",
    "i \n",
    "13291  NA07045\n",
    "# Press esc\n",
    ":x\n",
    "# Press enter\n",
    "\n",
    "# ATP\n",
    "vi ATP_0.2_low_call_rate_pihat.txt\n",
    "i \n",
    "13291  NA07045\n",
    "# Press esc\n",
    ":x\n",
    "# Press enter\n",
    "\n",
    "# CIDR\n",
    "vi CIDR_0.2_low_call_rate_pihat.txt\n",
    "i \n",
    "13291  NA07045\n",
    "# Press esc\n",
    ":x\n",
    "# Press enter\n",
    "\n",
    "# DUKE\n",
    "vi DUKE_0.2_low_call_rate_pihat.txt\n",
    "i \n",
    "13291  NA07045\n",
    "# Press esc\n",
    ":x\n",
    "# Press enter\n",
    "\n",
    "# GENEVA\n",
    "vi GENEVA_CASES_0.2_low_call_rate_pihat.txt\n",
    "i \n",
    "13291  NA07045\n",
    "# Press esc\n",
    ":x\n",
    "# Press enter\n",
    "\n",
    "vi GENEVA_CONTROLS_0.2_low_call_rate_pihat.txt\n",
    "i \n",
    "13291  NA07045\n",
    "# Press esc\n",
    ":x\n",
    "# Press enter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590eebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the individuals with the lowest call rate in 'related' pairs with a pihat > 0.2 \n",
    "# 0 non-founders in CanPath, CIDR, DUKE data, so we don't remove anything\n",
    "\n",
    "# OHS\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_auto_maf_hwe_founders --make-bed --out OHS_eye_s1_s2_sex_s3_s4\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_auto_maf_hwe_founders --make-bed --out BCGP_eye_s1_s2_sex_s3_s4\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_auto_maf_hwe_founders --make-bed --out ATL_eye_s1_s2_sex_s3_s4\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_auto_maf_hwe_founders --make-bed --out ATP_eye_s1_s2_sex_s3_s4\n",
    "\n",
    "# CIDR\n",
    "./plink --bfile CIDR_eye_s1_s2_sex_s3_auto_maf_hwe_founders --make-bed --out CIDR_eye_s1_s2_sex_s3_s4_CLEAN\n",
    "\n",
    "# DUKE\n",
    "./plink --bfile DUKE_eye_s1_s2_sex_s3_auto_maf_hwe_founders --make-bed --out DUKE_eye_s1_s2_sex_s3_s4_CLEAN\n",
    "\n",
    "# GENEVA\n",
    "./plink --bfile GENEVA_CASES_eye_s1_s2_sex_s3_auto_maf_hwe_founders --make-bed --out GENEVA_CASES_eye_s1_s2_sex_s3_s4_CLEAN\n",
    "./plink --bfile GENEVA_CONTROLS_eye_s1_s2_sex_s3_auto_maf_hwe_founders --make-bed --out GENEVA_CONTROLS_eye_s1_s2_sex_s3_s4_CLEAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca0348",
   "metadata": {},
   "source": [
    "### STEP 5\n",
    "This is according to the Marees et al. tutorial:\n",
    "\n",
    "**Pruning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73be04de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n",
      "bash: ./plink: No such file or directory\n",
      "bash: =======================: command not found\n",
      "Fatal error: cannot open file 'check_heterozygosity_rate.R': No such file or directory\n",
      "bash: syntax error near unexpected token `('\n",
      "bash: syntax error near unexpected token `\"heterozygosity.pdf\"'\n",
      "bash: syntax error near unexpected token `('\n",
      "bash: syntax error near unexpected token `het$HET_RATE,'\n",
      "bash: syntax error near unexpected token `Rscript'\n",
      "bash: syntax error near unexpected token `('\n",
      "bash: syntax error near unexpected token `('\n",
      "bash: syntax error near unexpected token `('\n",
      "bash: syntax error near unexpected token `('\n",
      "bash: syntax error near unexpected token `het_fail,'\n",
      "sed: fail-het-qc.txt: No such file or directory\n",
      "bash: ./plink: No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "127",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "## Pruning done only on CanPath datasets. \n",
    "\n",
    "    # Therefore, to generate a list of non-(highly)correlated SNPs, we exclude high inversion regions (inversion.txt [High LD regions]) and prune the SNPs using the command --indep-pairwise.\n",
    "    # The parameters \"50 5 0.2\" stand for:  window size, number of SNPs to shift the window at each step, and multiple correlation coefficient for a SNP being regressed on all other SNPs simultaneously.\n",
    "\n",
    "# Don't delete the file indepSNP.prune.in\n",
    "\n",
    "# OHS\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_s4 --indep-pairwise 50 5 0.2 --out OHS_indepSNP\n",
    "./plink --bfile OHS_eye_s1_s2_sex_s3_s4 --extract OHS_indepSNP.prune.in --make-bed --out OHS_eye_s1_s2_sex_s3_s4_pruned\n",
    "\n",
    "# BCGP\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_s4 --indep-pairwise 50 5 0.2 --out BCGP_indepSNP\n",
    "./plink --bfile BCGP_eye_s1_s2_sex_s3_s4 --extract BCGP_indepSNP.prune.in --make-bed --out BCGP_eye_s1_s2_sex_s3_s4_pruned\n",
    "\n",
    "# ATL\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_s4 --indep-pairwise 50 5 0.2 --out ATL_indepSNP\n",
    "./plink --bfile ATL_eye_s1_s2_sex_s3_s4 --extract ATL_indepSNP.prune.in --make-bed --out ATL_eye_s1_s2_sex_s3_s4_pruned\n",
    "\n",
    "# ATP\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_s4 --indep-pairwise 50 5 0.2 --out ATP_indepSNP\n",
    "./plink --bfile ATP_eye_s1_s2_sex_s3_s4 --extract ATP_indepSNP.prune.in --make-bed --out ATP_eye_s1_s2_sex_s3_s4_pruned\n",
    "\n",
    "# done for now, then go to pca\n",
    "\n",
    "=======================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c6bf2",
   "metadata": {},
   "source": [
    "### Now that you're done, make sure to keep the following files:\n",
    "1. Binary file output (OHS_eye_s1_s2_sex_s3_s4_pruned or CIDR_eye_s1_s2_sex_s3_s4_CLEAN)\n",
    "2. indepSNP.prune.in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab43a3b3",
   "metadata": {},
   "source": [
    "# Preparing QC Output for Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec76b67a",
   "metadata": {},
   "source": [
    "**Create script files for steps 1 and 2 and name them something like:**\n",
    "\n",
    "1. \"vcf_convert.sh\"\n",
    "2. \"splitchr_index.sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9704f009",
   "metadata": {},
   "source": [
    "**1. Convert binary files to vcf using PLINK**\n",
    "\n",
    "Using a loop proved a little difficult so I did each dataset manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c391c34f",
   "metadata": {},
   "source": [
    "OHS, BCGP, ATL, ATP successfully imputed using TopMed.\n",
    "\n",
    "The dbGaP datasets suffered from strand flip and clumping issues, so there is a \"snps-only\" tag to exclude any multi-character alleles. Frank provided some files + code to fix strand flip issues, this is in the \"Imputation + dbGaP Imputation issues\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e61205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --account=def-wendtfra\n",
    "#SBATCH --time=15:00:00\n",
    "#SBATCH --job-name=new-convert-vcf\n",
    "#SBATCH --output=new-convert-vcf.out\n",
    "#SBATCH --error=new-convert-vcf.err\n",
    "#SBATCH --mail-user=brendan.newton@mail.utoronto.ca\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mem=10G\n",
    "\n",
    "module load StdEnv/2020 plink/1.9b_6.21-x86_64\n",
    "\n",
    "# Removing REF/ALT alleles that are not A,T,C,G\n",
    "#Convert PLINK binary files to VCF format directly\n",
    "plink --bfile /home/newtonb1/scratch/PLINK/plink_mac_20230116/OHS_eye_s1_s2_sex_s3_s4_pruned --snps-only 'just-acgt'--recode vcf --out OHS_pruned.vcf\n",
    "plink --bfile /home/newtonb1/scratch/PLINK/plink_mac_20230116/BCGP_eye_s1_s2_sex_s3_s4_pruned --snps-only 'just-acgt' --recode vcf --out BCGP_pruned.vcf\n",
    "plink --bfile /home/newtonb1/scratch/PLINK/plink_mac_20230116/ATL_eye_s1_s2_sex_s3_s4_pruned --snps-only 'just-acgt' --recode vcf --out ATL_pruned.vcf\n",
    "plink --bfile /home/newtonb1/scratch/PLINK/plink_mac_20230116/ATP_eye_s1_s2_sex_s3_s4_pruned --snps-only 'just-acgt' --recode vcf --out ATP_pruned.vcf\n",
    "plink --bfile /home/newtonb1/scratch/PLINK/plink_mac_20230116/DUKE_eye_s1_s2_sex_s3_s4_CLEAN --snps-only 'just-acgt' --recode vcf --out DUKE_pruned.vcf\n",
    "plink --bfile /home/newtonb1/scratch/PLINK/plink_mac_20230116/CIDR_eye_s1_s2_sex_s3_s4_CLEAN --snps-only 'just-acgt' --recode vcf --out CIDR_pruned.vcf\n",
    "plink --bfile /home/newtonb1/scratch/PLINK/plink_mac_20230116/GENEVA_CASES_eye_s1_s2_sex_s3_s4_CLEAN --snps-only 'just-acgt' --recode vcf --out GENEVA_CASES_pruned.vcf\n",
    "plink --bfile /home/newtonb1/scratch/PLINK/plink_mac_20230116/GENEVA_CONTROLS_eye_s1_s2_sex_s3_s4_CLEAN --snps-only 'just-acgt' --recode vcf --out GENEVA_CONTROLS_pruned.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648b76e4",
   "metadata": {},
   "source": [
    "**2. Separate by chromosome and index**\n",
    "\n",
    "This step is required because the input for TopMed must be split by chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e12a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --account=def-wendtfra\n",
    "#SBATCH --time=15:00:00\n",
    "#SBATCH --job-name=new-test-splitchr\n",
    "#SBATCH --output=new-test-splitchr.out\n",
    "#SBATCH --error=new-test-splitchr.err\n",
    "#SBATCH --mail-user=brendan.newton@mail.utoronto.ca\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mem=10G\n",
    "\n",
    "module load StdEnv/2020 gcc/9.3.0 samtools/1.17  bcftools/1.13\n",
    "\n",
    "#Define chromosome numbers and dataset names\n",
    "chr=( {1..22} )\n",
    "datasets=(\"OHS\" \"BCGP\" \"ATL\" \"ATP\" \"DUKE\" \"CIDR\" \"GENEVA_CASES\" \"GENEVA_CONTROLS\")\n",
    "\n",
    "# Loop over each chromosome and dataset\n",
    "for dataset in \"${datasets[@]}\"\n",
    "do\n",
    "        # Input VCF file name\n",
    "        input_vcf=\"${dataset}_pruned.vcf\"\n",
    "        compressed_vcf=\"${dataset}_pruned.vcf.gz\"\n",
    "        # Index before splitting by chromosome\n",
    "        bgzip -c ${input_vcf} > ${compressed_vcf}\n",
    "        bcftools index ${compressed_vcf}\n",
    "\n",
    "        for chr_num in \"${chr[@]}\"\n",
    "        do\n",
    "                # Output VCF file names\n",
    "                output_vcf=\"${dataset}-chr${chr_num}.vcf.gz\"\n",
    "                # Extract variants for current chromosome\n",
    "                bcftools view -r ${chr_num} ${compressed_vcf} | bgzip -c > ${output_vcf}\n",
    "                # Index again\n",
    "                bcftools index ${output_vcf}\n",
    "        done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df83d9e",
   "metadata": {},
   "source": [
    "At this point, we run the java code that Frank sent, in the \"Imputation + dbGaP Imputation issues\" file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Frank's files to Cedar with\n",
    "scp -r /Users/brendannewton/Desktop/WENDT_LAB/FSC485/FRANK_IMPUTATION newtonb1@cedar.computecanada.ca:/home/newtonb1/scratch/NEW_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=strandflip-fix\n",
    "#SBATCH --account=def-wendtfra\n",
    "#SBATCH --mem=1000\n",
    "#SBATCH --time=10:00:00\n",
    "#SBATCH --output=strandflip-fix.out\n",
    "#SBATCH --error=strandflip-fix.err\n",
    "#SBATCH --mail-user=brendan.newton@mail.utoronto.ca\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "#####DOWNLOADS#####\n",
    "#go to this website and download the JAVA executable at the bottom of the page: https://faculty.washington.edu/browning/conform-gt.html#use\n",
    "#also click on \"human reference panel\", click on \"b37.vcf\", download each of the .vcf.gz files for the autosomes. the .tbi files are not needed.\n",
    "#move everything into compute canada scratch directory\n",
    "\n",
    "#####THINGS TO CHANGE ABOUT YOUR INPUT DATA#####\n",
    "#this script will not accept anything in the dbGAP .vcf files that has a REF or ALT allele other than A, C, T, or G so you will need to remove those.\n",
    "#PLINK and VCFtools should both have something like a 'snps-only' flag that can help you do this pretty easily.\n",
    "\n",
    "#####SCRIPTS#####\n",
    "#Keep the .sh header of this file. You might need to modify the wall time but everything else should be ok to keep as is.\n",
    "module load plink/1.9b_6.21-x86_64\n",
    "module load vcftools/0.1.16\n",
    "module load java/17.0.2\n",
    "\n",
    "java -Xmx8g -jar /home/wendtfra/conform-gt.24May16.cee.jar ref=chr22.1kg.phase3.v5a.vcf gt=DUKE_chr22.vcf.gz chrom=22 out=new.chr22 excludesamples=non.eur.excl\n",
    "\n",
    "chr=( {1..22} )\n",
    "datasets=(\"OHS\" \"BCGP\" \"ATL\" \"ATP\" \"DUKE\" \"CIDR\" \"GENEVA_CASES\" \"GENEVA_CONTROLS\")\n",
    "\n",
    "for dataset in \"${datasets[@]}\"\n",
    "do\n",
    "    for chr_num in \"${chr[@]}\"\n",
    "    do\n",
    "        java -Xmx8g -jar /home/newtonb1/scratch/NEW_INDEX/conform-gt.24May16.cee.jar ref=chr${chr}.1kg.phase3.v5a.vcf.gz gt=${dataset}_chr${chr}.vcf.gz chrom=22 out=${dataset}_new.chr${chr} excludesamples=non.eur.excl\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf4ede",
   "metadata": {},
   "source": [
    "OHS, BCGP, ATL, ATP should successfully impute without having to remove SNPs.\n",
    "\n",
    "The java script will compare the alleles with the reference sample and, if different, will switch A1 and A2 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9769b3",
   "metadata": {},
   "source": [
    "## Moving File Directory to Cedar\n",
    "\n",
    "**Use the following command in your local home directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66101cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scp -r /Users/brendannewton/Desktop/WENDT_LAB/FSC485/UNIMPUTED newtonb1@cedar.computecanada.ca:/home/newtonb1/scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fcfe8e",
   "metadata": {},
   "source": [
    "Alternatively, you can use MobaXTerm or CyberDuck to move/create/delete folders and files easily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6097ab",
   "metadata": {},
   "source": [
    "## Post-Imputation QC + Merge\n",
    "\n",
    "**dbGap Imputation issues not fixed, move to use CanPath data. These commands were not used (provided by Cristina) but would have been to perform steps missing between Imputation and PCA.**\n",
    "\n",
    "Can also use IMMerge for the merging step: https://academic.oup.com/bioinformatics/article/39/1/btac750/6839927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract list of variants to reduce missingness in merged file:\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --account=def-eparra\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --job-name=extract-variant-list\n",
    "#SBATCH --output=extract-variant-list.out\n",
    "#SBATCH --mail-user=c.abbatangelo@mail.utoronto.ca\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mem=20G\n",
    "\n",
    "module load StdEnv/2020 htslib/1.17\n",
    "\n",
    "# chr${i}.Axiom.R2-clean.recode.vcf.gz\n",
    "# chr${i}.CartaGene-clean.recode.vcf.gz\n",
    "\n",
    "# Loop through the files using the naming convention chr1.vcf.gz, chr2.vcf.gz\n",
    "for i in {1..22}; do\n",
    "    vcf_file=\"chr${i}.Axiom.R2-clean.recode.vcf.gz\"\n",
    "    output_txt=\"variant_list_chr${i}.txt\"\n",
    "\n",
    "    # Use grep to extract variant lines and append to the output file\n",
    "    zcat \"$vcf_file\" | grep -v \"^#\" | cut -f 1-5 >> \"$output_txt\"\n",
    "\n",
    "    echo \"Variant list generation for chr${i} complete.\"\n",
    "done\n",
    "\n",
    "echo \"All variant lists generated.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --account=def-eparra\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --job-name=extract-variant-list-chr1\n",
    "#SBATCH --output=extract-variant-list-chr1.out\n",
    "#SBATCH --error=#SBATCH --output=extract-variant-list-chr1.err\n",
    "#SBATCH --mail-user=c.abbatangelo@mail.utoronto.ca\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mem=20G\n",
    "\n",
    "module load StdEnv/2020 htslib/1.17 tabix/0.2.6\n",
    "\n",
    "# Copy header lines from the original VCF file to the output file\n",
    "zcat chr1.CartaGene-clean.recode.vcf.gz | grep \"^#\" > chr1.CartaGene-clean-varlist.vcf\n",
    "\n",
    "# Use grep to filter variants from dataset 2 using the variant list\n",
    "zcat chr1.CartaGene-clean.recode.vcf.gz | grep -Ff variant_list_chr1.txt >> chr1.CartaGene-clean-varlist.vcf\n",
    "\n",
    "# Compress the output VCF file\n",
    "bgzip chr1.CartaGene-clean-varlist.vcf\n",
    "\n",
    "# Index the compressed VCF file using tabix\n",
    "tabix -p vcf chr1.CartaGene-clean-varlist.vcf.gz\n",
    "\n",
    "echo \"Variant extraction for chr1 from dataset 2 complete.\"\n",
    "\n",
    "## Turn this into a loop or array to do multiple chromosomes at one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724be9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge:\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --account=def-eparra\n",
    "#SBATCH --time=15:00:00\n",
    "#SBATCH --job-name=merge-chr1  \n",
    "#SBATCH --output=merge-chr1.out\n",
    "#SBATCH --error=merge-chr1.err\n",
    "#SBATCH --mail-user=c.abbatangelo@mail.utoronto.ca\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mem=20G\n",
    "\n",
    "module load StdEnv/2020  gcc/9.3.0 bcftools/1.16\n",
    "module load tabix/0.2.6\n",
    "\n",
    "# Command suggested by G. Debortoli bcftools concat file1.vcf file2.vcf -Oz > all_chr.vcf.gz\n",
    "\n",
    "#gzip -d chr22.CartaGene-clean-varlist.vcf.gz\n",
    "\n",
    "#bgzip chr22.CartaGene-clean-varlist.vcf\n",
    "\n",
    "    vcf_file1=\"chr1.Axiom.R2-clean.recode.vcf.gz\"\n",
    "    vcf_file2=\"chr1.CartaGene-clean-varlist.vcf.gz\"\n",
    "    output_file=\"chr1-merged-AllCanPath.vcf.gz\"\n",
    "\n",
    "    # Merge VCF files using vcftools\n",
    "    bcftools merge \"$vcf_file1\" \"$vcf_file2\" -Oz > \"$output_file\"\n",
    "\n",
    "    # Index the merged VCF file\n",
    "    #tabix -p vcf chr22-merged-AllCanPath.vcf.gz\n",
    "\n",
    "    echo \"Merged chr1 complete.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a49ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Final QC:\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --account=def-eparra\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH --job-name=final-autosome-qc\n",
    "#SBATCH --array=1-22\n",
    "#SBATCH --output=final-autosome-qc.out\n",
    "#SBATCH --error=final-autosome-qc.err\n",
    "#SBATCH --mail-user=c.abbatangelo@mail.utoronto.ca\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mem=100G\n",
    "\n",
    "module load StdEnv/2020 gcc/9.3.0 bcftools/1.13 vcftools/0.1.16 tabix/0.2.6\n",
    "\n",
    "# Input VCF file\n",
    "input_vcf=\"chr${SLURM_ARRAY_TASK_ID}-merged-AllCanPath.vcf.gz\"\n",
    "\n",
    "# Output filtered and compressed VCF file\n",
    "output_filtered=\"chr${SLURM_ARRAY_TASK_ID}_merged_AllCanPath_clean.vcf.gz\"\n",
    "\n",
    "# Filtering using vcftools\n",
    "vcftools --gzvcf \"$input_vcf\" --maf 0.005 --hwe 1e-6 --max-missing 0.98 --recode --recode-INFO-all --stdout | bgzip -c > \"$output_filtered\"\n",
    "\n",
    "# Indexing the filtered and compressed VCF file using tabix\n",
    "tabix -p vcf \"$output_filtered\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c49b829",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "PLINK --pca flag was ported from GCTA. Generates plink.eigenvec and plink.eigenval files.\n",
    "\n",
    "These can be run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b87970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "./plink --pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d09fa",
   "metadata": {},
   "source": [
    "# Relevant PLINK input documentation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be3d4ea",
   "metadata": {},
   "source": [
    "### --keep info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep <filename(s)...>\n",
    "--remove <filename(s)...>\n",
    "--keep-fam <filename(s)...>\n",
    "--remove-fam <filename(s)...>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792065e",
   "metadata": {},
   "source": [
    "--keep accepts one or more space/tab-delimited text files with sample IDs, and removes all unlisted samples from the current analysis; --remove does the same for all listed samples. Similarly, --keep-fam and --remove-fam accept text files with family IDs in the first column, and keep or remove entire families.\n",
    "\n",
    "--keep/--remove now support a wider variety of sample ID file formats:\n",
    "\n",
    "If the first line starts with '#FID' or '#IID', it will be treated as a header line. As long as the first columns are \"#FID IID\", \"#FID IID SID\", \"#IID\", or \"#IID SID\", PLINK 2 will do the right thing. (Note that when FID is undefined, it is treated as '0'.)\n",
    "If there is no header line, one-column lines are treated as IIDs, and multicolumn lines are treated the same way as in PLINK 1.x (first two columns assumed to be FID/IID)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f791e9",
   "metadata": {},
   "source": [
    "**Phenotype/covariate-based**\n",
    "\n",
    "--keep-if removes all samples which don't satisfy a comparison predicate on a phenotype or covariate, while --remove-if does the reverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89952a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "--keep-if <phenotype/covariate name> <operator> <value>\n",
    "--remove-if <phenotype/covariate name> <operator> <value>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55c4d01",
   "metadata": {},
   "source": [
    "Syntax and treatment of missing values is the same as for --extract-if-info.\n",
    "For binary phenotypes, either '2' or 'case' (any capitalization) can be used to refer to cases, and either '1', 'ctrl', or 'control' can be used to refer to controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88595e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "--require-pheno [phenotype name(s)...]\n",
    "--require-covar [covariate name(s)...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1bb2f",
   "metadata": {},
   "source": [
    "When parameters are provided, --require-pheno removes samples missing any of the named phenotypes; otherwise, it removes samples missing any loaded phenotype. --require-covar does the same things for covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470b147",
   "metadata": {},
   "source": [
    "### Missing genotype rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcded0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "--geno [maximum per-variant]\n",
    "--mind [maximum per-sample]\n",
    "--oblig-missing <variant x block file> <block definition file>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec47ea7",
   "metadata": {},
   "source": [
    "--geno filters out all variants with missing call rates exceeding the provided value (default 0.1) to be removed, while --mind does the same for samples.\n",
    "\n",
    "--oblig-missing lets you specify blocks of missing genotype calls for --geno and --mind to ignore. The first file should be a text file with variant IDs in the first column and block names in the second, while the second file should be in .clst format. See the PLINK 1.07 documentation for examples. (--oblig-clusters is a deprecated way to specify --oblig-missing's second parameter.)\n",
    "\n",
    "If any genotype calls in a block are not actually missing, PLINK now reports an error; use --zero-cluster if you want to force those calls to missing instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320fdc8a",
   "metadata": {},
   "source": [
    "### MAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "--maf [minimum freq]\n",
    "--max-maf <maximum freq>\n",
    "--mac <minimum count>\n",
    "  (alias: --min-ac)\n",
    "--max-mac <maximum count>\n",
    "  (alias: --max-ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b8e30",
   "metadata": {},
   "source": [
    "--maf filters out all variants with minor allele frequency below the provided threshold (default 0.01), while --max-maf imposes an upper MAF bound. Similarly, --mac and --max-mac impose lower and upper minor allele count bounds, respectively.\n",
    "\n",
    "Only founders are normally considered by these filters; use --nonfounders to change this.\n",
    "\n",
    "--maf-succ\n",
    "\n",
    "--maf-succ causes primary minor allele frequencies to be estimated via the \"rule of succession\" employed by EIGENSOFT. I.e.,\n",
    "\n",
    "   qhat := (1 + <observed minor allele count>) / (2 + <total observations>)\n",
    "\n",
    "instead of the usual\n",
    "\n",
    "   qhat := <observed minor allele count> / <total observations>.\n",
    "\n",
    "This flag does not affect stratified MAF computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f07deb0",
   "metadata": {},
   "source": [
    "### HWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "--hwe <p-value> ['midp'] ['include-nonctrl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f75dfb",
   "metadata": {},
   "source": [
    "--hwe filters out all variants which have Hardy-Weinberg equilibrium exact test p-value below the provided threshold. We recommend setting a low thresholdâ€”serious genotyping errors often yield extreme p-values like 1e-50 which are detected by any reasonable configuration of this test, while genuine SNP-trait associations can be expected to deviate slightly from Hardy-Weinberg equilibrium (so it's dangerous to choose a threshold that filters out too many variants). This HWE p-value calculator may be helpful.\n",
    "\n",
    "--hwe's 'midp' modifier applies the mid-p adjustment described in Graffelman J, Moreno V (2013) The mid p-value in exact tests for Hardy-Weinberg equilibrium. The mid-p adjustment tends to bring the null rejection rate in line with the nominal p-value, and also reduces the filter's tendency to favor retention of variants with missing data. We recommend its use.\n",
    "\n",
    "Because of the missing data issue, you should not apply a single p-value threshold across a batch of variants with highly variable missing call rates. A warning is now given whenever observation counts vary by more than 10%.\n",
    "\n",
    "Only founders are considered by this test; use --nonfounders to change this. Also, with case/control data, cases and missing phenotypes are normally ignored; override this with 'include-nonctrl'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e6b3d",
   "metadata": {},
   "source": [
    "### --freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "--freq [{counts | case-control}] ['gz']\n",
    "--freqx ['gz']\n",
    "  (alias: --frqx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df9c87",
   "metadata": {},
   "source": [
    "By itself, --freq writes a minor allele frequency report to plink.frq. If you add the 'counts' modifier, an allele count report is written to plink.frq.count instead. Alternatively, you can use --freq with --within/--family to write a cluster-stratified frequency report to plink.frq.strat, or use the 'case-control' modifier to write a case/control phenotype-stratified report to plink.frq.cc.\n",
    "\n",
    "--freqx writes a more informative genotype count report to plink.frqx.\n",
    "\n",
    "For both flags, gzipped output can be requested with the 'gz' modifier.\n",
    "\n",
    "Nonfounders are normally excluded from these counts/frequencies; use --nonfounders to change this.\n",
    "\n",
    "All of these reports (except for --freq + --within/--family) are valid input for --read-freq; --freqx is the most powerful when used in that capacity, since it preserves deviation from Hardy-Weinberg equilibrium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6a118d",
   "metadata": {},
   "source": [
    "### --extract and --exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da4cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "--extract ['range'] <filename>\n",
    "--exclude ['range'] <filename>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432ebf2",
   "metadata": {},
   "source": [
    "--extract normally accepts a text file with a list of variant IDs (usually one per line, but it's okay for them to just be separated by spaces), and removes all unlisted variants from the current analysis.\n",
    "\n",
    "With the 'range' modifier, the input file should be in set range format instead.\n",
    "\n",
    "--exclude does the same for all listed variants. Note that this is slightly different from PLINK 1.07's behavior when the main input fileset contains duplicate variant IDs: PLINK 1.9 removes all matches, while PLINK 1.07 just removes one of the matching variants. If your intention is to resolve duplicates, you should now use --bmerge instead of --exclude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a98c34",
   "metadata": {},
   "source": [
    "### --range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea34ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plink --file data --extract myrange.txt --range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d4277f",
   "metadata": {},
   "source": [
    "--range is a modifier for --extract and --exclude. If the --range flag is added, then instead of a list of SNPs, PLINK will expect a list of chromosomal ranges to be given instead, one per line.\n",
    "\n",
    "All SNPs within that range will then be excluded or extracted. The format of myrange.txt should be, one range per line, whitespace-separated:\n",
    "\n",
    "     CHR     Chromosome code (1-22, X, Y, XY, MT, 0)     \n",
    "     BP1     Start of range, physical position in base units     \n",
    "     BP2     End of range, as above     \n",
    "     LABEL   Name of range/gene\n",
    "     \n",
    "For example,\n",
    "\n",
    "     2 30000000 35000000  R1\n",
    "     2 60000000 62000000  R2     \n",
    "     X 10000000 20000000  R3\n",
    "     \n",
    "would extract/exclude all SNPs in these three regions (5Mb and 2Mb on chromosome 2 and 10Mb on chromosome X)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e90f39",
   "metadata": {},
   "source": [
    "### --snps-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "--snps-only ['just-acgt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383dbc8",
   "metadata": {},
   "source": [
    "--snps-only excludes all variants with one or more multi-character allele codes. With 'just-acgt', variants with single-character allele codes outside of {'A', 'C', 'G', 'T', 'a', 'c', 'g', 't', } are also excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a9170",
   "metadata": {},
   "source": [
    "### --pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f26af",
   "metadata": {},
   "outputs": [],
   "source": [
    "--pca [count] ['header'] ['tabs'] ['var-wts']\n",
    "--pca-cluster-names <name(s)...>\n",
    "--pca-clusters <filename>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8911c",
   "metadata": {},
   "source": [
    "By default, --pca extracts the top 20 principal components of the variance-standardized relationship matrix; you can change the number by passing a numeric parameter. Eigenvectors are written to plink.eigenvec, and top eigenvalues are written to plink.eigenval. The 'header' modifier adds a header line to the .eigenvec file(s), and the 'tabs' modifier makes the .eigenvec file(s) tab- instead of space-delimited. You can request variant weights with the 'var-wts' modifier, and dump the matrix by using --pca in combination with --make-rel/--make-grm-gz/--make-grm-bin.\n",
    "\n",
    "For other instructions see: https://www.cog-genomics.org/plink/1.9/strat#pca"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
